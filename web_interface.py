from flask import render_template_string


def html_index():
    html_content = """
    <!DOCTYPE html>
    <html lang="pt-BR">
    <head>
        <meta charset="UTF-8">
        <title>Eu Digital</title>
    </head>
    <body>
        <h1>ğŸ¤ Fale com o Eu Digital</h1>
        <button id="startBtn">ğŸ™ï¸ ComeÃ§ar GravaÃ§Ã£o</button>
        <p id="status">Aguardando interaÃ§Ã£o...</p>
        <audio id="responseAudio" controls></audio>

        <script>
            let mediaRecorder;
            let audioChunks = [];

            const startBtn = document.getElementById("startBtn");
            const statusPara = document.getElementById("status");
            const responseAudio = document.getElementById("responseAudio");

            startBtn.onclick = async () => {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(stream);
                const analyser = audioContext.createAnalyser();
                source.connect(analyser);
                analyser.fftSize = 512;

                const dataArray = new Uint8Array(analyser.frequencyBinCount);

                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                statusPara.textContent = "ğŸ™ï¸ Gravandoâ€¦";

                mediaRecorder.ondataavailable = e => audioChunks.push(e.data);

                mediaRecorder.onstop = async () => {
                    statusPara.textContent = "â³ Enviando para IAâ€¦";

                    const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
                    const formData = new FormData();
                    formData.append("file", audioBlob, "gravacao.webm");

                    try {
                        const response = await fetch("/audio", {
                            method: "POST",
                            body: formData,
                        });

                        if (!response.ok) {
                            console.error("âŒ Erro na resposta da IA:", response.statusText);
                            alert("Erro ao processar o Ã¡udio.");
                            return;
                        }

                        const audioBuffer = await response.blob();
                        responseAudio.src = URL.createObjectURL(audioBuffer);
                        responseAudio.play();
                        statusPara.textContent = "âœ… Resposta recebida!";
                    } catch (err) {
                        console.error("âŒ Erro na requisiÃ§Ã£o:", err);
                        alert("Erro ao enviar Ã¡udio.");
                        statusPara.textContent = "âš ï¸ Erro ao enviar.";
                    }
                };

                mediaRecorder.start();

                let silentSeconds = 0;
                const silenceThreshold = 0.02;
                const checkInterval = 200;

                const checkSilence = setInterval(() => {
                    analyser.getByteFrequencyData(dataArray);
                    const avgVolume = dataArray.reduce((a, b) => a + b) / dataArray.length / 256;

                    if (avgVolume < silenceThreshold) {
                        silentSeconds += checkInterval;
                        if (silentSeconds >= 5000) {
                            clearInterval(checkSilence);
                            mediaRecorder.stop();
                            audioContext.close();
                            statusPara.textContent = "ğŸ›‘ SilÃªncio detectado. GravaÃ§Ã£o encerrada.";
                        }
                    } else {
                        silentSeconds = 0;
                    }
                }, checkInterval);
            };
        </script>
    </body>
    </html>
    """
    return render_template_string(html_content)
